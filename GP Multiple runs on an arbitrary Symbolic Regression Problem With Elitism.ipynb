{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "GP Multiple runs on an arbitrary Symbolic Regression Problem With Elitism.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/conorlime/CS6271/blob/main/GP%20Multiple%20runs%20on%20an%20arbitrary%20Symbolic%20Regression%20Problem%20With%20Elitism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSIwN3iVGjp4"
      },
      "source": [
        "# GP Multiple runs on an arbitrary Symbolic Regression Problem with Elitism."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJkBlPvoGjp7"
      },
      "source": [
        "Now we add elitism to our system. Note that this is packaged up as an other algorithm, so it will work with virtually any other notebook we've looked at. \n",
        "\n",
        "The key thing to note is how we include that functionality, as it is **not** a standard algorithm in DEAP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDBltZdKGjp8",
        "outputId": "68cfe966-610e-4379-bc51-a21e3c982159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nmBuYxnGjp-"
      },
      "source": [
        "Install DEAP. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvuDyCPVGjp-",
        "outputId": "f4d01ae1-cf90-4739-8f88-89d568f2883e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install deap"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deap\n",
            "  Downloading deap-1.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 22.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 20 kB 27.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 30 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 40 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 51 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 61 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 71 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 81 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 92 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 102 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 112 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 122 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 133 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 143 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 153 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 160 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap) (1.19.5)\n",
            "Installing collected packages: deap\n",
            "Successfully installed deap-1.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbwx74bsEKjl"
      },
      "source": [
        "Clone the data folder from the class git repository and create a local copy for us to read. This is the same process we used for the Symbolic Regression example; in fact, in this notebook, we are bringing in both data **and** code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bj4JuDiyEXtf",
        "outputId": "1473adde-34cb-46d4-cd43-01587987505a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSS-hNz7Er4o"
      },
      "source": [
        "Clone the class repository. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbZZ7keoE1og",
        "outputId": "2ae5fb55-bb5c-49c5-d84c-a839659fd402"
      },
      "source": [
        "!git clone https://github.com/conorlime/CS6271"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CS6271'...\n",
            "remote: Enumerating objects: 150, done.\u001b[K\n",
            "remote: Counting objects: 100% (150/150), done.\u001b[K\n",
            "remote: Compressing objects: 100% (144/144), done.\u001b[K\n",
            "remote: Total 150 (delta 58), reused 16 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (150/150), 2.65 MiB | 7.41 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz85I_NBFxZD",
        "outputId": "17946327-7b21-4f73-9d27-a9ca717a7d59"
      },
      "source": [
        "cd CS6271/Notebooks/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'CS6271/Notebooks/'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYponIvjL4Sd"
      },
      "source": [
        "Let's take a look at what's in here, but only at the directories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQpPdNaYF59x",
        "outputId": "fa8aeb9c-026c-4e87-f79d-18fef5269f69"
      },
      "source": [
        "ls -l|grep drw"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drwxr-xr-x 5 root root 4096 Sep 10 14:53 \u001b[0m\u001b[01;34mCS6271\u001b[0m/\n",
            "drwx------ 6 root root 4096 Sep 10 14:53 \u001b[01;34mdrive\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Sep  1 19:26 \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5neW4U0MgAG"
      },
      "source": [
        "Python will import from files in the working directory, so we change to that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RumA1HDvMpq2",
        "outputId": "3b25eb8a-ae1c-4d4e-da42-b0b045864de5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd Utilities/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'Utilities/'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3L8T1zFIGjp-"
      },
      "source": [
        "Import our tools. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdSAV57LGjp-",
        "outputId": "ef805643-1761-4288-c1aa-fcefe9073fcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "import operator\n",
        "import math\n",
        "import random\n",
        "\n",
        "import numpy\n",
        "\n",
        "from deap import algorithms\n",
        "from deap import base\n",
        "from deap import creator\n",
        "from deap import tools\n",
        "from deap import gp\n",
        "\n",
        "import csv\n",
        "from elitism import eaSimpleWithElitism\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import itertools\n",
        "import networkx as nx\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a9091e42d1b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0melitism\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meaSimpleWithElitism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'elitism'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGd9qrZ7Gjp_"
      },
      "source": [
        "Set our Genetic Programming parameters, one of which is now the number of runs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONxoU3YPGjp_"
      },
      "source": [
        "# Genetic Programming constants:\n",
        "POPULATION_SIZE = 20\n",
        "P_CROSSOVER = 0.9\n",
        "P_MUTATION = 0.01\n",
        "MAX_GENERATIONS = 50\n",
        "HALL_OF_FAME_SIZE = 10\n",
        "\n",
        "N_RUNS = 5\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpYkNOJhGjqA"
      },
      "source": [
        "Set the random seed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8Jtg3dkGjqA"
      },
      "source": [
        "RANDOM_SEED = 412\n",
        "random.seed(RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wifI-T6kGjqA"
      },
      "source": [
        "GP-Specific constants."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChInW_CSGjqA"
      },
      "source": [
        "MIN_TREE_HEIGHT = 3\n",
        "MAX_TREE_HEIGHT = 5\n",
        "LIMIT_TREE_HEIGHT = 17\n",
        "MUT_MIN_TREE_HEIGHT = 0\n",
        "MUT_MAX_TREE_HEIGHT = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbUkXzQGGjqB"
      },
      "source": [
        "Read in the data. Notice that this time we can use the path, so there's no need to change to that folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjmjH_9lGjqB"
      },
      "source": [
        "with open(\"../data/randomData.csv\") as symbRegData:\n",
        "    n_rows = sum(1 for line in symbRegData)\n",
        "with open(\"../data/randomData.csv\") as symbRegData:\n",
        "    reader = csv.reader(symbRegData)\n",
        "    data = list(list(float(elem) for elem in row) for row in reader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xJMGs3DGjqB"
      },
      "source": [
        "Define our fitness function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHLUtCiXGjqC"
      },
      "source": [
        "def evalSymbReg(individual):\n",
        "    # Transform the tree expression in a callable function\n",
        "    func = toolbox.compile(expr=individual)\n",
        "    # Evaluate the sum of squared difference between the expression and the target values\n",
        "    diff = sum((func(*row[:-1]) - row[-1])**2 for row in data)\n",
        "    error = diff/n_rows\n",
        "    if (error>10):\n",
        "        error=10\n",
        "    #return error, individual.height\n",
        "    nodes, edges, labels = gp.graph(individual)\n",
        "    return error, len(nodes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLtYRyMrGjqC"
      },
      "source": [
        "Define a protected division function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArYOGP_wGjqC"
      },
      "source": [
        "def protectedDiv(left, right):\n",
        "    try:\n",
        "        return left / right\n",
        "    except ZeroDivisionError:\n",
        "        return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6SAXjClGjqC"
      },
      "source": [
        "Add our functions and terminals. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9u14j2pGjqC"
      },
      "source": [
        "pset = gp.PrimitiveSet(\"MAIN\", 5) # number of inputs!!!\n",
        "pset.addPrimitive(operator.add, 2)\n",
        "pset.addPrimitive(operator.sub, 2)\n",
        "pset.addPrimitive(operator.mul, 2)\n",
        "pset.addPrimitive(protectedDiv, 2)\n",
        "pset.addPrimitive(operator.neg, 1)\n",
        "pset.addPrimitive(math.cos, 1)\n",
        "pset.addPrimitive(math.sin, 1)\n",
        "pset.addEphemeralConstant(\"rand101\", lambda: random.random())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHiMXv81GjqD"
      },
      "source": [
        "Create our toolbox. This is very similar to the Symbolic Regression notebook except we are using the parameters declared up above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7oxd_o7GjqD"
      },
      "source": [
        "toolbox = base.Toolbox()\n",
        "\n",
        "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,-1.0))\n",
        "creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMin)\n",
        "\n",
        "toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=2)\n",
        "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "toolbox.register(\"compile\", gp.compile, pset=pset)\n",
        "\n",
        "toolbox.register(\"evaluate\", evalSymbReg)\n",
        "#toolbox.register(\"select\", tools.selNSGA2)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=5)\n",
        "\n",
        "toolbox.register(\"mate\", gp.cxOnePoint)\n",
        "toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=5)\n",
        "toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr_mut, pset=pset)\n",
        "\n",
        "toolbox.decorate(\"mate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=17))\n",
        "toolbox.decorate(\"mutate\", gp.staticLimit(key=operator.attrgetter(\"height\"), max_value=17))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIN1Kt9LGjqD"
      },
      "source": [
        "Create our statistics. These are a bit more complex than the GA ones because we want to keep track of fitness and size for all runs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngxh9qZZGjqE"
      },
      "source": [
        "maxListFitness = []\n",
        "avgListFitness = []\n",
        "minListFitness = []\n",
        "stdListFitness = []\n",
        "\n",
        "maxListSize = []\n",
        "avgListSize = []\n",
        "minListSize = []\n",
        "stdListSize = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61OpiUL0GjqE"
      },
      "source": [
        "Now the magic happens and we run **N_RUNS** times. Always start with a small number of runs and generations to make sure that everything is working properly before you commit to a larger number. That way, if something goes horribly wrong, Python won't replicate it 30 times before giving you back control!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdGVxTgJGjqE"
      },
      "source": [
        "for r in range(0, N_RUNS):\n",
        "    population = toolbox.population(n=POPULATION_SIZE)\n",
        "    # define the hall-of-fame object:\n",
        "    hof = tools.HallOfFame(HALL_OF_FAME_SIZE)   \n",
        "\n",
        "\n",
        "    # Create our statistics\n",
        "    stats_fit = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "    stats_size = tools.Statistics(len)\n",
        "    mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size)\n",
        "    mstats.register(\"avg\", numpy.mean)\n",
        "    mstats.register(\"std\", numpy.std)\n",
        "    mstats.register(\"min\", numpy.min)\n",
        "    mstats.register(\"max\", numpy.max)\n",
        "    \n",
        "    \n",
        "    # Which run are we on?\n",
        "    print(\"\\n\\nCurrently on run\", r, \"of\",N_RUNS)\n",
        "    \n",
        "    \n",
        "    # It's usually a good idea to turn off verbose when conducting multiple runs\n",
        "    population, logbook = eaSimpleWithElitism(population,\n",
        "                                                  toolbox,\n",
        "                                                  cxpb=P_CROSSOVER,\n",
        "                                                  mutpb=P_MUTATION,\n",
        "                                                  ngen=MAX_GENERATIONS,\n",
        "                                                  stats=mstats,\n",
        "                                                  halloffame=hof,\n",
        "                                                  verbose=False)\n",
        "    \n",
        "    #maxFitnessValues, meanFitnessValues = logbook.chapters['fitness'].select(\"min\", \"avg\")\n",
        "    meanFitnessValues, stdFitnessValues, minFitnessValues, maxFitnessValues  = logbook.chapters['fitness'].select(\"avg\", \"std\", \"min\", \"max\")\n",
        "    meanSizeValues, stdSizeValues, minSizeValues, maxSizeValues  = logbook.chapters['size'].select(\"avg\", \"std\", \"min\", \"max\")\n",
        "\n",
        "\n",
        "    # Save statistics for this run:\n",
        "    avgListFitness.append(meanFitnessValues)\n",
        "    stdListFitness.append(stdFitnessValues)\n",
        "    minListFitness.append(minFitnessValues)\n",
        "    maxListFitness.append(maxFitnessValues)\n",
        "    \n",
        "    avgListSize.append(meanSizeValues)\n",
        "    stdListSize.append(stdSizeValues)\n",
        "    minListSize.append(minSizeValues)\n",
        "    maxListSize.append(maxSizeValues)\n",
        "\n",
        "    # print info for best solution found:\n",
        "    best = hof.items[0]\n",
        "    print(\"-- Best Individual = \", best)\n",
        "    print(\"-- length={}, height={}\".format(len(best), best.height))\n",
        "    print(\"-- Best Fitness = \", best.fitness.values[0])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5J5D6jTGjqF"
      },
      "source": [
        "Create our graphs using the averages across all the runs. Notice how we use standard deviation to show how much variation there is in the runs. \n",
        "\n",
        "Notice that if there's a big discrepancy between best and average the graphs can look like there's virtually no variation in the best score. If this happens, the first thing to do is verify if that is actually happening; you can do that by commenting out this line:\n",
        "\n",
        "**plt.errorbar(x, avgArray.mean(0), yerr=stdArray.mean(0),label=\"Average\",color=\"Red\")**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "o8ISz9X0GjqF"
      },
      "source": [
        "# Genetic Programming is done (all runs) - plot statistics:\n",
        "x = numpy.arange(0, MAX_GENERATIONS+1)\n",
        "avgArray = numpy.array(avgListFitness)\n",
        "stdArray = numpy.array(stdListFitness)\n",
        "minArray = numpy.array(minListFitness)\n",
        "maxArray = numpy.array(maxListFitness)\n",
        "plt.xlabel('Generation')\n",
        "plt.ylabel('Fitness')\n",
        "plt.title('Best and Average Fitness for Symbolic Regression')\n",
        "#plt.errorbar(x, avgArray.mean(0), yerr=stdArray.mean(0),label=\"Average\",color=\"Red\")\n",
        "plt.errorbar(x, minArray.mean(0), yerr=minArray.std(0),label=\"Best\", color=\"Green\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ2iyZokGjqF"
      },
      "source": [
        "Show the graph for size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLarxt_2GjqF"
      },
      "source": [
        "# Genetic Programming is done (all runs) - plot statistics:\n",
        "x = numpy.arange(0, MAX_GENERATIONS+1)\n",
        "avgArray = numpy.array(avgListSize)\n",
        "stdArray = numpy.array(stdListSize)\n",
        "minArray = numpy.array(minListSize)\n",
        "maxArray = numpy.array(maxListSize)\n",
        "plt.xlabel('Generation')\n",
        "plt.ylabel('Size')\n",
        "plt.title('Best and Average Size for Symbolic Regression')\n",
        "plt.errorbar(x, avgArray.mean(0), yerr=stdArray.mean(0),label=\"Average\",color=\"Red\")\n",
        "plt.errorbar(x, minArray.mean(0), yerr=minArray.std(0),label=\"Best\", color=\"Blue\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}